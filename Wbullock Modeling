---
title: "Home Credit EDA and Model Analysis"
author: "Whitney Bullock" 
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: "none"
    toc: true
    toc_depth: 3
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,      
  warning = FALSE,   
  message = FALSE,   
  error = FALSE,     
  fig.width = 7,
  fig.height = 5
)
```

## Business Problem

Home Credit: Predictive Analysis to Identify Loan Repayment-
Ready Customers

Business Problem Statement

Home Credit is a financial services provider specializing in lending to individuals with little or no credit history, empowering them with easy and safe access to financing. It is crucial for Home Credit to accurately assess a customer’s ability to repay in order to identify reliable target customers. By effectively predicting repayment capability, Home Credit can responsibly extend credit to a larger customer base while minimizing financial risk to the company and its investors.

Benefit

The benefits of accurately predicting target customers are as follows:

1. Maximized customer base

2. Minimized financial risk of defaulting customers

3. Empowerment of customers to have financial freedom


Analytics Approach

I will leverage the comprehensive dataset available on Kaggle to develop a supervised learning model. The objective is to accurately classify target customers based on their likelihood to repay, enabling more informed decision-making in credit risk assessment. The primary measure of success for this project will be the model’s ability to accurately identify customers’ repayment capabilities. I propose aiming for at least a 95% repayment success rate among customers classified as target customers through the data-driven analysis at the one-year marker.

In addition to core application data, the project will incorporate alternative data sources provided within the Kaggle dataset — such as behavioral patterns, previous credit histories, and external bureau data. These features provide deeper insights into customer habits and financial behavior. The alternative data will help to improve model performance and also identify underserved yet creditworthy individuals.  

Scope and Deliverables

This project will focus exclusively on the data sets provided by Kaggle. The primary deliverable will be a robust analytical assessment of potential customers’ ability to repay loans. Additionally, the project will produce a detailed list of customer metrics and features that are key indicators for identifying target customers for Home Credit.

Project Details

This project will be executed by Whitney Bullock, University of Utah Business Analytics graduate student. The project will be completed on or before December 10, 2025.

Following is a list of project milestones

1. Business problem statement

2. Exploratory data analysis

3. Decision tree analysis

4. Presentation

5. Final report



## Installing packages and libraries 

```{r}
#loading packages and libraries 

packages <- c("tidyverse", "skimr", "DataExplorer", "corrplot", "naniar","caret", "tidymodels","xgboost")
install.packages(setdiff(packages, rownames(installed.packages())))


library(tidyverse)
library(skimr)
library(DataExplorer)
library(corrplot)
library(naniar)
library(DataExplorer)
library(ggplot2)
library(caret)
library(tidymodels)
library(xgboost)
```

## Loading Data 
```{r}
#reading in data from various files  

test <- read.csv("application_test.csv")
train <- read.csv("application_train.csv")
```

## Summary Data
```{r}
#general summary data to become familiar with the dataset 
str(train)
glimpse(train)
skim(train)
```

## Exploratory Data Analysis 
### Checking for Target Balance 

Target variable explained: Target variable (1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample, 0 - all other cases)

This chart is a visual representation of the client's ability to repay the loan. It is easy to notice a large amount of clients are able to repay the loan. 

In the distribution of the target variable you can quickly identify that 91.92% of clients repay their loan. 

What we want to explore through the data analysis is what key variables can we use to predict customers who will likely be able and follow through with loan re-payment.  Are they married, single, male, female, how old are they, do they live in a house, apartment, own a car, don't own a car.  We want to highlight the perfect client to ensure we are making offers of loans to those who have the highest percentage of repaying the loan.  


```{r}
table(train$TARGET)

prop.table(table(train$TARGET))

ggplot(train, aes(x = factor(TARGET))) +
  geom_bar(fill = "skyblue") +
  labs(title = "Distribution of TARGET Variable", x = "TARGET", y = "Count") +
  theme_minimal()
```

### Verifying Target Distribution 
```{r}
#simple target variable distribution 

target_dist <- prop.table(table(train$TARGET)) * 100
target_dist
```

### Explore relationship between Target and Predictors 

The numeric correlations indicating that the normalized external source information is negatively correlated with the target variable.  Additionally, days since birth is positively correlated at 0.078.(remember days are negative values) This suggest that people younger in age may default on the loan.  The same is for days employed, the lower amount of days employed has a negative correlation expecting people with less days of employment to have a higher rate of default. Even the idea of more days since their last phone change could be a good predictor of their ability to repay the loan.  

This loops gives insight to the categories the clients fall into.  90.48% of the clients are requesting cash loans.  Some quick information at a glance is that 65% of requesters are female, 63% indicate they own real estate, 65% state they don't own a car, the majority of the client list are working, on a pension, or a commercial associate. 75% have at least secondary education, 24% have higher education.  Finally, it appears that laborers request the loans at a higher rate, this could be a product of their working schedule fluctuations or inconsistent flow of finances.  

```{r}
#correlation to identify top predictor variables for loan repayment. 

numeric_cols <- train %>%
  select(where(is.numeric))

correlations <- sapply(numeric_cols, function(x) cor(x, train$TARGET, use = "complete.obs"))

cor_df <- data.frame(Variable = names(correlations), Correlation = correlations) %>%
  mutate(Correlation = round(Correlation, 3)) %>%
  arrange(desc(abs(Correlation)))

head(cor_df, 12)
```


```{r}
# loop to identify different categorical variable outcomes for loan repayment.  

cat_vars <- names(train)[sapply(train, function(x) is.character(x) | is.factor(x))]

# Loop through each categorical variable
for (var in cat_vars) {
  cat("====", var, "====\n")
  
  # Create a summary table of counts by TARGET
  summary_table <- train %>%
    group_by(.data[[var]], TARGET) %>%
    summarise(Count = n(), .groups = "drop") %>%
    mutate(Percent = round(Count / sum(Count) * 100, 2))
  
  print(summary_table)
  cat("\n\n")
}
```

## Missing Values 

I first identified which variables were missing information and considered the reasons why information would be missing.  I chose to imput the median value for EXT_SOURCE_1 and then proceeded to remove variables with more than 50% missing values. By imputting a value in EXT_SOURCE_1 it removed it from the list of variables to be removed.   By removing variables that are over 50% incomplete the dataset has been cleaned up and ensures that the remaining variables are more likely to provide useful insights, rather than contributing noise or requiring excessive imputation and computation.

As a result of this cleaning process, the number of variables has been reduced from 123 to 85. The remaining 85 variables each contain responses from at least 50% of participants, making them more reliable for analysis.

```{r}
# verifying what variables have missing data.  

missing_train <- train %>%
  summarise(across(everything(), ~ round(mean(is.na(.)), 3))) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "MissingRate") %>%
  arrange(desc(MissingRate))

head(missing_train, 40)

```

```{r}
# because ext_source_1 was identified as a good predictor for loan repayment, I am choosing to use an imput value for the missing information.  This way the variable will will not be removed when I run the 50% threshold.  

med <- median(train$EXT_SOURCE_1, na.rm = TRUE)

train$export_source_1_imputed <- ifelse(is.na(train$EXT_SOURCE_1),
                                        med,
                                        train$EXT_SOURCE_1)

head(train[c("EXT_SOURCE_1", "export_source_1_imputed")])
```


```{r}
# removing variables that have a large amount of missing values 

threshold <- 0.5
vars_to_drop <- missing_train %>%
  filter(MissingRate > threshold) %>%
  pull(Variable)

train_cleaned <- train %>% select(-all_of(vars_to_drop))
```

```{r}
skim(train_cleaned)
```

## Data Sanity Check 

```{r}
#summarizing the data to see if the numerical values make senes in the data.  

summary(train_cleaned)
```

Need to address negative days within variables: DAYS_BIRTH, DAYS_EMPLOYED, DAYS_REGISTRATION, DAYS_ID_PUBLISH

```{r}
#cleaning the data to make the dates make sense, rather than negative days. 

train_cleaned <- train_cleaned %>%
  mutate(AGE_YEARS = abs(DAYS_BIRTH) / 365)

train_cleaned <- train_cleaned %>%
  mutate(YEARS_EMPLOYED = abs(DAYS_EMPLOYED) / 365 )

train_cleaned <- train_cleaned %>%
  mutate(YEARS_REGISTERED = abs(DAYS_REGISTRATION)/365)

train_cleaned <- train_cleaned %>% 
  mutate(YEARS_PUBLISH = abs (DAYS_ID_PUBLISH)/365)

```

```{r}
summary(train_cleaned$AGE_YEARS)
summary(train_cleaned$YEARS_EMPLOYED)
summary(train_cleaned$YEARS_REGISTERED)
summary(train_cleaned$YEARS_PUBLISH)
```

Years employed has an outlier that we need to locate 


```{r}
train_cleaned <- train_cleaned %>%
  mutate(DAYS_EMPLOYED = ifelse(DAYS_EMPLOYED == 365243, NA, DAYS_EMPLOYED),
         YEARS_EMPLOYED = abs(DAYS_EMPLOYED) / 365)
```

```{r}
summary(train_cleaned$YEARS_EMPLOYED)
```

This identifies that of the 307511 applicants in the data 55374 are either unemployed or retired.  18% 


### Coorelation after cleaning 

Re-running the correlation of numeric values after cleaning the data to see if any correlations have changed.  This reconfirms that ext. source, age, and years of employment all are good indicators to identify if the client will or will not repay the loan.  

```{r}
#re-running the coorelation to see if the top list of predictors would change when variables with missing information were removed.  

numeric_cols <- train_cleaned %>%
  select(where(is.numeric))

correlations <- sapply(numeric_cols, function(x) cor(x, train_cleaned$TARGET, use = "complete.obs"))

cor_df <- data.frame(Variable = names(correlations), Correlation = correlations) %>%
  mutate(Correlation = round(Correlation, 3)) %>%
  arrange(desc(abs(Correlation)))

head(cor_df, 12)
```

## AI 

### AI Prompt and COL names given 

Prompt used (exact)

You are a credit risk analyst. Below are the column names from my dataset. Based only on the meaning of the variables (no data yet), list the top 15–20 variables you think will be most predictive of the binary target TARGET (1 = default/bad, 0 = good). For each chosen variable give one sentence explaining why you expect it to be predictive. Also list any variables you believe are unlikely to be predictive and why. Finally, identify obvious interactions or non-linear relationships that should be considered later in modeling.

Column names:
SK_ID_CURR, TARGET, NAME_CONTRACT_TYPE, CODE_GENDER, FLAG_OWN_CAR, FLAG_OWN_REALTY, CNT_CHILDREN, AMT_INCOME_TOTAL, AMT_CREDIT, AMT_ANNUITY, AMT_GOODS_PRICE, NAME_TYPE_SUITE, NAME_INCOME_TYPE, NAME_EDUCATION_TYPE, NAME_FAMILY_STATUS, NAME_HOUSING_TYPE, REGION_POPULATION_RELATIVE, DAYS_BIRTH, DAYS_EMPLOYED, DAYS_REGISTRATION, DAYS_ID_PUBLISH, OWN_CAR_AGE, FLAG_MOBIL, FLAG_EMP_PHONE, FLAG_WORK_PHONE, FLAG_CONT_MOBILE, FLAG_PHONE, FLAG_EMAIL, OCCUPATION_TYPE, CNT_FAM_MEMBERS, REGION_RATING_CLIENT, REGION_RATING_CLIENT_W_CITY, WEEKDAY_APPR_PROCESS_START, HOUR_APPR_PROCESS_START, REG_REGION_NOT_LIVE_REGION, REG_REGION_NOT_WORK_REGION, LIVE_REGION_NOT_WORK_REGION, REG_CITY_NOT_LIVE_CITY, REG_CITY_NOT_WORK_CITY, LIVE_CITY_NOT_WORK_CITY, ORGANIZATION_TYPE, EXT_SOURCE_1, EXT_SOURCE_2, EXT_SOURCE_3, APARTMENTS_AVG, BASEMENTAREA_AVG, YEARS_BEGINEXPLUATATION_AVG, YEARS_BUILD_AVG, COMMONAREA_AVG, ELEVATORS_AVG, ENTRANCES_AVG, FLOORSMAX_AVG, FLOORSMIN_AVG, LANDAREA_AVG, LIVINGAPARTMENTS_AVG, LIVINGAREA_AVG, NONLIVINGAPARTMENTS_AVG, NONLIVINGAREA_AVG, APARTMENTS_MODE, BASEMENTAREA_MODE, YEARS_BEGINEXPLUATATION_MODE, YEARS_BUILD_MODE, COMMONAREA_MODE, ELEVATORS_MODE, ENTRANCES_MODE, FLOORSMAX_MODE, FLOORSMIN_MODE, LANDAREA_MODE, LIVINGAPARTMENTS_MODE, LIVINGAREA_MODE, NONLIVINGAPARTMENTS_MODE, NONLIVINGAREA_MODE, APARTMENTS_MEDI, BASEMENTAREA_MEDI, YEARS_BEGINEXPLUATATION_MEDI, YEARS_BUILD_MEDI, COMMONAREA_MEDI, ELEVATORS_MEDI, ENTRANCES_MEDI, FLOORSMAX_MEDI, FLOORSMIN_MEDI, LANDAREA_MEDI, LIVINGAPARTMENTS_MEDI, LIVINGAREA_MEDI, NONLIVINGAPARTMENTS_MEDI, NONLIVINGAREA_MEDI, FONDKAPREMONT_MODE, HOUSETYPE_MODE, TOTALAREA_MODE, WALLSMATERIAL_MODE, EMERGENCYSTATE_MODE, OBS_30_CNT_SOCIAL_CIRCLE, DEF_30_CNT_SOCIAL_CIRCLE, OBS_60_CNT_SOCIAL_CIRCLE, DEF_60_CNT_SOCIAL_CIRCLE, DAYS_LAST_PHONE_CHANGE, FLAG_DOCUMENT_2, FLAG_DOCUMENT_3, FLAG_DOCUMENT_4, FLAG_DOCUMENT_5, FLAG_DOCUMENT_6, FLAG_DOCUMENT_7, FLAG_DOCUMENT_8, FLAG_DOCUMENT_9, FLAG_DOCUMENT_10, FLAG_DOCUMENT_11, FLAG_DOCUMENT_12, FLAG_DOCUMENT_13, FLAG_DOCUMENT_14, FLAG_DOCUMENT_15, FLAG_DOCUMENT_16, FLAG_DOCUMENT_17, FLAG_DOCUMENT_18, FLAG_DOCUMENT_19, FLAG_DOCUMENT_20, FLAG_DOCUMENT_21, AMT_REQ_CREDIT_BUREAU_HOUR, AMT_REQ_CREDIT_BUREAU_DAY, AMT_REQ_CREDIT_BUREAU_WEEK, AMT_REQ_CREDIT_BUREAU_MON, AMT_REQ_CREDIT_BUREAU_QRT, AMT_REQ_CREDIT_BUREAU_YEAR

### AI response 

AI response (semantic ranking — top 20 variables with short reasoning)

EXT_SOURCE_3 — external credit-scoring features are usually highly predictive because they synthesize credit bureau/third-party signals about borrower risk.

EXT_SOURCE_2 — an additional external score often provides complementary predictive information to EXT_SOURCE_3.

EXT_SOURCE_1 — another external score; together the three EXT_SOURCE variables commonly dominate predictive power.

DAYS_BIRTH — borrower age (days) correlates with experience, income stability and default behavior (often non-linear).

AMT_CREDIT — loan amount is directly related to repayment burden and default probability (higher credit often higher risk ceteris paribus).

AMT_INCOME_TOTAL — household income is fundamental to repayment capacity and moderates other financial ratios.

AMT_ANNUITY — monthly/annual payment size relative to income indicates stress; high annuity-to-income increases default risk.

AMT_GOODS_PRICE — loan purpose/size proxy; when large relative to income it raises risk.

DAYS_EMPLOYED — employment tenure (and special sentinel values) captures job stability; short/irregular employment increases risk.

CNT_CHILDREN — dependents increase household obligations and can reduce repayment capacity.

CNT_FAM_MEMBERS — household size changes per-capita income dynamics and consumption burden.

NAME_INCOME_TYPE — income source (pension, state, working, business) strongly affects stability and default propensity.

NAME_EDUCATION_TYPE — education proxies for earning capacity and financial literacy, correlating with risk.

NAME_HOUSING_TYPE — housing status (own, mortgage, rent) proxies wealth/stability and collateral availability.

OCCUPATION_TYPE — job category captures industry/role risk and stability (e.g., seasonal work).

DAYS_ID_PUBLISH — recency of identity issuance may capture recency of life events / identity stability and sometimes correlates with fraud/risk.

REGION_RATING_CLIENT / REGION_RATING_CLIENT_W_CITY — regional socio-economic indicators capture local unemployment/credit environment (either one if choose).

OBS_60_CNT_SOCIAL_CIRCLE — observations in social circle may indicate social-financial exposures; high observation counts can be informative of shared risk.

DEF_60_CNT_SOCIAL_CIRCLE — defaults observed in social circle are plausible contagion indicators of risk.

AMT_REQ_CREDIT_BUREAU_YEAR (also MON/QRT/WEEK) — recent credit inquiries reflect active credit shopping and short-term credit stress; year aggregate is often most informative.

Note: I focused on variables that (by domain knowledge) capture borrower ability to pay, historical credit signals, external bureau scores, and household obligations.

Variables likely to be weak or require special handling

SK_ID_CURR — identifier only, no predictive content (drop or use for joins).

FLAG_MOBIL / many FLAG_DOCUMENT_ fields* — these are often almost-constant (e.g., FLAG_MOBIL = 1 for most) and have low variance; include only if their distribution shows signal.

WEEKDAY_APPR_PROCESS_START / HOUR_APPR_PROCESS_START — could be spurious unless application-time correlates with channel/fraud; usually weak.

Highly aggregated census-style *_MODE, *_MEDI, *_AVG — could be useful, but many are derived from applicant’s neighborhood and can be redundant with REGION_*; treat carefully.

BASEMENTAREA_ / COMMONAREA_ etc.** — building-level averages may be noisy or frequently missing; predictive only if well-populated and aligned with applicant address.

FLAG_EMAIL / FLAG_PHONE — if nearly all are 1/0 they carry little info; but missingness patterns might be informative.

Suggested interactions & non-linearities to consider

Annuity / Income interaction: AMT_ANNUITY / AMT_INCOME_TOTAL (annuity-to-income ratio) — expected strong non-linear effect.

Credit / Income / Age triad: AMT_CREDIT × AMT_INCOME_TOTAL × DAYS_BIRTH — same loan may be riskier for younger/low-income customers.

EXT_SOURCEs combined: non-linear combination or monotonic binning of EXT_SOURCE_1/2/3 often beats single-score use.

Employment & Income Type: DAYS_EMPLOYED × NAME_INCOME_TYPE — short employment may be more severe for wage-earners than for pensioners.

Region × Housing: REGION_RATING_CLIENT × NAME_HOUSING_TYPE — regional economic conditions interact with housing tenure to change risk.

Counts extreme effects: CNT_CHILDREN, CNT_FAM_MEMBERS may show non-linear (both 0 and very large values could behave differently); consider binning.

Brief critique of the AI (this response) reasoning — strengths & limits

Strengths

Pulls from established credit-risk domain logic: ability-to-pay (income, annuity), historical risk (EXT_SOURCEs, observed defaults), and stability signals (age, employment, housing).

Suggests both point variables and interactions (ratios and cross-terms) that are commonly important in credit models.

Avoids obvious traps (IDs, near-constant flags) and flags census/aggregate fields for careful handling.

Weaknesses / What this semantic pass cannot do

No empirical signal quantification: variable rankings are hypothetical — we don’t know effect sizes, distributions, missingness, outliers, or multicollinearity until we inspect the data.

Potential redundancy: several suggested variables are correlated (e.g., AMT_CREDIT vs AMT_GOODS_PRICE; EXT_SOURCEs among themselves); the semantic list does not resolve redundancy.

Data quirks not captured: special sentinel values (e.g., DAYS_EMPLOYED = 365243 used in some datasets) or heavy missingness could invert the expected importance.

Proxy leakage risk: some fields (application processing metadata, organization type, or recently added bureau fields) can leak label information if TARGET was collected in overlapping time windows — a data-timeline check is needed.

Practical next steps (what I recommend you do now)

Run the statistical path: compute univariate separation (box/density plots), AUC/KS, and counts by category for the variables above — this will confirm which of the semantic picks actually carry signal.

Check missingness & sentinel values: calculate % missing and look for sentinel constants (e.g., DAYS_EMPLOYED flagged as special).

Create derived features: annuity-to-income, credit-to-income, age in years, employment-length-in-years, binned EXT_SOURCE scores, etc.

Check multicollinearity: correlation matrix + VIF among the top candidate features, then prune or combine redundant ones.

Fit a quick regularized model and tree-based model (L1-logistic, random forest or XGBoost) and examine coefficients / SHAP to confirm feature importance and interactions.

If you want, I can immediately (a) run the semantic prompt again but include short descriptions for any columns you want to emphasize, or (b) proceed to the data-informed statistical exploration — just upload data.csv (with TARGET) and I’ll run the analyses (plots, AUCs, ranked list) and return the visual report and a CSV of ranked features. Which would you like next?

### My response to the AI generation 

The AI identified very similar predictors as I had identified in my EDA.  Both the AI any myself through EDA identified external sources as being strong predictors of the client's ability to repay the loan.   Both AI and myself also highlighted the idea that age would be a good predictor of a persons ability to repay.  The AI highlighted a predictor of AMT_CREDIT as a good predictor, which did not come through in my EDA as a possible predictor. Other variables that the AI chose to focus on was the borrowers credit score and their total income.  The AI believes if the client has more money, they are likely to be able to repay the loan. Through my EDA the city was highlighted as a potential predictor as well as the days since last phone change; neither of these were listed in the AI generated list. It is very interesting to see the balance between both my EDA and the AI generated list.  By using actual data more insightful conclusions can be drawn out of the data.  


## Venn Diagram 

```{r}
#drawing a venn diagram to compare what the AI thought would be good predictors and what the data actually identified as predictors. 

library(VennDiagram)

AI_Predictor_Variables <- c("EXT_SOURCE_3", "EXT_SOURCE_2", "EXT_SOURCE_1", "DAYS_BIRTH", "AMT_CREDIT", "AMT_INCOME_TOTAL")
Data_Predictor_Variables <- c("EXT_SOURCE_3", "EXT_SOURCE_2", "EXT_SOURCE_1", "DAYS-BIRTH", "DAYS_EMPLOYED", "REGION_RATING_CLIENT_W_CITY")

venn.plot <- venn.diagram(
  x = list(
    "AI-Predictors" = AI_Predictor_Variables,
    "Data-Predictors" = Data_Predictor_Variables
  ),
  filename = NULL,
  fill = c("skyblue", "lightgreen"),
  alpha = 0.5,
  cex = 1.5,
  cat.cex = 1.2
)

grid::grid.draw(venn.plot)

```


## EDA Results 

Through my exploratory data analysis (EDA) of home-credit, I have identified some promising predictor variables for preferred client profiles. External sources were highlighted in both my EDA and the AI generated list as being really good predictors to identify clients and their ability to repay the loan as agreed.  When supplying the model with actual data, I was able to gain further insight that age, days employed, and days since last phone change could be used to more accurately predict who Home Credit should enter into loan contracts with. I believe the more time utilized during the EDA process helps to draw out more meaningful connections and understanding of the data.  It also helps the user to identify more nuanced data and learn more about what type of clients Home Credit's core customer base is. Through EDA I am able to paint a picture of each user and how Home Credit is helping fund their dreams, day to day lives, and future plans.  


## Model Analysis 

To start Model analysis it has been established that the current benchmark for Home Credit is 91.92% clients receiving a loan and successfully completing repayment, while 8.07% clients default on their repayment.   Through model analysis and variable tuning the goal is to achieve 94% successful client repayment.  

For my modeling analyses I will be randomly reducing the data set to 5000 samples so that my models can run quickly to determine which are starting to perform better than others and not have the computing bogged down by the 30,000 observations. In some models you will see a 70:30 data partition split into training and test data. This is a very important step to withhold some of the data to be able to test our predictions once the model in question has been trained.  

### Logistic Regression Model 

The first model I will be testing is a simple logistic regression model with previously identified  predictors: EXT_SOURCE_3, EXT_SOURCE_2, EXPORT_SOURCES_1_IMPUTED, AGE_YEAR, YEARS_EMPLOYED.  The log regression model will help to confirm if the selected variables are considered to be statistically significant and their impact on the target.  


```{r}
#setting seed so data is repeatable 

set.seed(1234)
# Split into training (70%) and testing (30%)
train_index <- sample(1:nrow(train_cleaned), 0.7 * nrow(train_cleaned))
train_data <- train_cleaned[train_index, ]
test_data <- train_cleaned[-train_index, ]
```

```{r}
#logistics regression model using pre-identified variables as being potential predictors to identify customers who potentially will default on loan repayment.  

log_model1 <- glm(train_data$TARGET ~ train_data$EXT_SOURCE_3 + train_data$EXT_SOURCE_2 + train_data$export_source_1_imputed + train_data$AGE_YEARS + train_data$YEARS_EMPLOYED, data = train_data)
summary(log_model1)

exp(coef(log_model1))

log_model2 <- glm(train_data$TARGET ~ train_data$CODE_GENDER, data = train_data)
summary(log_model2)

exp(coef(log_model2))

log_model3 <- glm(train_data$TARGET ~ train_data$AMT_INCOME_TOTAL, data = train_data)
summary(log_model3)
```

```{r}
#predictor models 
predictors_model1 <- c("EXT_SOURCE_3", "EXT_SOURCE_2", "export_source_1_imputed", 
                       "AGE_YEARS", "YEARS_EMPLOYED")
predictors_model2 <- "CODE_GENDER"
predictors_model3 <- "AMT_INCOME_TOTAL"

library(pROC)

validate_model <- function(model, test_data, predictors) {
  test_data_clean <- test_data[complete.cases(test_data[, predictors]), ]
  preds <- predict(model, newdata = test_data_clean, type = "response")
  test_data_clean$TARGET <- as.numeric(as.character(test_data_clean$TARGET))
  roc_obj <- roc(test_data_clean$TARGET, preds)
  auc_val <- auc(roc_obj)
  return(list(roc = roc_obj, auc = auc_val, n = nrow(test_data_clean)))
}

log_model1 <- glm(TARGET ~ EXT_SOURCE_3 + EXT_SOURCE_2 + export_source_1_imputed +
                  AGE_YEARS + YEARS_EMPLOYED, data = train_data, family = binomial)

log_model2 <- glm(TARGET ~ CODE_GENDER, data = train_data, family = binomial)

log_model3 <- glm(TARGET ~ AMT_INCOME_TOTAL, data = train_data, family = binomial)

result1 <- validate_model(log_model1, test_data, predictors_model1)
result2 <- validate_model(log_model2, test_data, predictors_model2)
result3 <- validate_model(log_model3, test_data, predictors_model3)

result1$auc
result2$auc
result3$auc

plot(result1$roc, col = "blue", main = "ROC Curves for Logistic Models")
plot(result2$roc, col = "red", add = TRUE)
plot(result3$roc, col = "green", add = TRUE)
legend("bottomright", legend = c("Model 1: EXT_SOURCE & Age/Employment", 
                                 "Model 2: CODE_GENDER", 
                                 "Model 3: AMT_INCOME_TOTAL"),
       col = c("blue", "red", "green"), lwd = 2)

```


### Logistic Regression Model Analysis 

In Model 1, all variables are highly statistically significant. In particular, higher external credit scores are strongly associated with a lower probability of loan default, while employment status and age have smaller but still meaningful effects. When examining gender alone, the model yields an AUC only slightly above 0.5, indicating that gender by itself provides almost no predictive power for loan default. Similarly, a model based solely on income also produces an AUC barely above random chance. Overall, these results suggest that while certain predictors such as external credit scores are highly informative, individual characteristics like gender or income are insufficient on their own to predict default.

### Decision Tree Model  

Because we have labeled data, I will use a supervised machine learning decision tree algorithm, to model the relationship between the features Home Credit has values for and our target variable. I have chosen to try a decision tree model because it can handle my variables both numeric and categorical.  It also is not influenced by outliers. 

For the decision tree I need to adjust for target imbalance to ensure the model effectively identifies defaulters, preventing bias toward the majority class.  For this model I have chosen a set value of 5x for the defaulters to better learn from them.  

```{r}
library(rpart)
library(rpart.plot)
```

```{r}


class_weights <- ifelse(train_data$TARGET == 1, 5, 1) 

tree_model <- rpart(TARGET ~ EXT_SOURCE_3 + EXT_SOURCE_2 + export_source_1_imputed +
                    AGE_YEARS + YEARS_EMPLOYED,
                    data = train_data,
                    method = "class",
                    weights = class_weights,
                    control = rpart.control(minsplit = 20, cp = 0.001))
rpart.plot(tree_model, type = 2, extra = 104, fallen.leaves = TRUE, cex = 0.7)
tree_model
```


```{r}
predictors <- c("EXT_SOURCE_3", "EXT_SOURCE_2", "export_source_1_imputed",
                "AGE_YEARS", "YEARS_EMPLOYED")

test_data_clean <- test_data[complete.cases(test_data[, predictors]), ]

tree_probs <- predict(tree_model, newdata = test_data_clean, type = "prob")[,2]
tree_class <- ifelse(tree_probs >= 0.5, 1, 0)

roc_tree <- roc(test_data_clean$TARGET, tree_probs)
auc_val <- auc(roc_tree)
print(paste("AUC:", round(auc_val, 4)))

plot(roc_tree, main = "ROC Curve for Weighted Decision Tree")
```


### Decision Tree Model Analysis 
With the weighted values assigned to the minority class I achieved a AUC of .6853.  The predictive performance was lower in the decision tree model. That said, there is still very useful information obtained from the model.  In particular it can identify key characteristics to use for identifying high-risk segments such as low external source values, perhaps allowing for automatic rejection values to speed the approval and denial process for Home Credit. 

## Conclusion 

Key insights identified through my analysis is that external credit scores are the most powerful predictors for loan default risk.  The higher the score, the lower the probability of loan default.  Age and employment duration have smaller but meaningful contributions.  My analysis suggests that older, more experienced customers are slightly less likely to default on the loan. Individual characteristics like gender and income when analyzed in isolation have unreliable predictive power, no better than a 50/50 coin flip.  

The log model with more variables showed decent performance for predictive accuracy.  The weighted tree performed slightly below the log model1, but did provide valuable insights in terms of class recognition.  

I will continue with other models to see if predictive power can be increased. Looking into models such as random forest or gradient boosted trees to combine interpretability and predictive power. I hope to be able to develop a model that Home Credit can better target high-risk customers while improving overall approval efficiency.  


